<?xml version="1.0"?>
<Container version="2">
  <Name>tdarr_node</Name>
  <Repository>haveagitgat/tdarr_node</Repository>
  <Registry>https://hub.docker.com/r/haveagitgat/tdarr_node/</Registry>
  <Network>host</Network>
  <MyIP/>
  <Shell>sh</Shell>
  <Privileged>false</Privileged>
  <Support>https://forums.unraid.net/topic/84070-support-haveagitgat-tdarr-audiovideo-library-analytics-transcode-automation/</Support>
  <Project>https://github.com/HaveAGitGat/Tdarr</Project>
  <Overview>(tdarr server required separately) Tdarr V2 is a distributed transcoding system for automating media library transcode/remux management and making sure your files are exactly how you need them to be in terms of codecs/streams/containers and so on. Put your spare hardware to use with Tdarr Nodes for Windows, Linux (including Linux arm) and macOS. &#xD;
[br][br]&#xD;
Designed to work alongside applications like Sonarr/Radarr and built with the aim of modularisation, parallelisation and scalability, each library you add has its own transcode settings, filters and schedule. Workers can be fired up and closed down as necessary, and are split into 4 types - Transcode CPU/GPU and Health Check CPU/GPU. Worker limits can be managed by the scheduler as well as manually. &#xD;
[br][br]&#xD;
For a desktop application with similar functionality please see HBBatchBeast.&#xD;
[br][br]&#xD;
Docs here: https://tdarr.io/docs/&#xD;
[br][br]&#xD;
Plugins here: https://github.com/HaveAGitGat/Tdarr_Plugins&#xD;
[br][br]&#xD;
&#xD;
  </Overview>
  <Category>Productivity: MediaApp:Video</Category>
  <WebUI/>
  <Icon>https://github.com/ground7/docker-templates/blob/master/img/tdarr-node.png?raw=true</Icon>
  <ExtraParams>--runtime=nvidia</ExtraParams>
  <PostArgs/>
  <CPUset/>
  <DateInstalled>1612251504</DateInstalled>
  <Description>(tdarr server required separately) Tdarr V2 is a distributed transcoding system for automating media library transcode/remux management and making sure your files are exactly how you need them to be in terms of codecs/streams/containers and so on. Put your spare hardware to use with Tdarr Nodes for Windows, Linux (including Linux arm) and macOS. &#xD;
[br][br]&#xD;
Designed to work alongside applications like Sonarr/Radarr and built with the aim of modularisation, parallelisation and scalability, each library you add has its own transcode settings, filters and schedule. Workers can be fired up and closed down as necessary, and are split into 4 types - Transcode CPU/GPU and Health Check CPU/GPU. Worker limits can be managed by the scheduler as well as manually. &#xD;
[br][br]&#xD;
For a desktop application with similar functionality please see HBBatchBeast.&#xD;
[br][br]&#xD;
Docs here: https://tdarr.io/docs/&#xD;
[br][br]&#xD;
Plugins here: https://github.com/HaveAGitGat/Tdarr_Plugins&#xD;
[br][br]&#xD;
&#xD;
  </Description>
  <Networking>
    <Mode>host</Mode>
    <Publish>
      <Port>
        <HostPort>8266</HostPort>
        <ContainerPort>8266</ContainerPort>
        <Protocol>tcp</Protocol>
      </Port>
      <Port>
        <HostPort>8267</HostPort>
        <ContainerPort>8267</ContainerPort>
        <Protocol>tcp</Protocol>
      </Port>
    </Publish>
  </Networking>
  <Data>
    <Volume>
      <HostDir>/mnt/user/appdata/tdarr_node/config</HostDir>
      <ContainerDir>/app/configs</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
    <Volume>
      <HostDir>/mnt/user/appdata/tdarr_node/logs</HostDir>
      <ContainerDir>/app/logs</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
    <Volume>
      <HostDir>/mnt/user/media/local/</HostDir>
      <ContainerDir>/media</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
    <Volume>
      <HostDir>/mnt/user/temp/tdarr_transcode/</HostDir>
      <ContainerDir>/temp</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
  </Data>
  <Environment>
    <Variable>
      <Value>0.0.0.0</Value>
      <Name>serverIP</Name>
      <Mode/>
    </Variable>
    <Variable>
      <Value>0.0.0.0</Value>
      <Name>nodeIP</Name>
      <Mode/>
    </Variable>
    <Variable>
      <Value>99</Value>
      <Name>PUID</Name>
      <Mode/>
    </Variable>
    <Variable>
      <Value>100</Value>
      <Name>PGID</Name>
      <Mode/>
    </Variable>
    <Variable>
      <Value>GPU-01981fdf-d4b2-4e74-ed8c-c3dcb8629146</Value>
      <Name>NVIDIA_VISIBLE_DEVICES</Name>
      <Mode/>
    </Variable>
    <Variable>
      <Value>all</Value>
      <Name>NVIDIA_DRIVER_CAPABILITIES</Name>
      <Mode/>
    </Variable>
    <Variable>
      <Value>LoyalSlaveNode</Value>
      <Name>nodeID</Name>
      <Mode/>
    </Variable>
  </Environment>
  <Labels/>
  <Config Name="Server IP" Target="serverIP" Default="0.0.0.0" Mode="" Description="Server IP. Required if using Tdarr Nodes across your local network" Type="Variable" Display="always" Required="false" Mask="false">0.0.0.0</Config>
  <Config Name="Server Port" Target="8266" Default="8266" Mode="tcp" Description="Server Port" Type="Port" Display="always" Required="false" Mask="false">8266</Config>
  <Config Name="Node IP" Target="nodeIP" Default="0.0.0.0" Mode="" Description="Node IP. Required if using Tdarr Nodes across your local network" Type="Variable" Display="always" Required="false" Mask="false">0.0.0.0</Config>
  <Config Name="Node Port" Target="8267" Default="8267" Mode="tcp" Description="Node Port" Type="Port" Display="always" Required="false" Mask="false">8267</Config>
  <Config Name="PUID" Target="PUID" Default="99" Mode="" Description="Container Variable: PUID" Type="Variable" Display="always" Required="false" Mask="false">99</Config>
  <Config Name="PGID" Target="PGID" Default="100" Mode="" Description="Container Variable: PGID" Type="Variable" Display="always" Required="false" Mask="false">100</Config>
  <Config Name="Configs" Target="/app/configs" Default="" Mode="rw" Description="Container Path: /app/configs" Type="Path" Display="always" Required="false" Mask="false">/mnt/user/appdata/tdarr_node/config</Config>
  <Config Name="Logs" Target="/app/logs" Default="" Mode="rw" Description="Container Path: /app/logs" Type="Path" Display="always" Required="false" Mask="false">/mnt/user/appdata/tdarr_node/logs</Config>
  <Config Name="Media Library" Target="/media" Default="" Mode="rw" Description="Container Path: /media" Type="Path" Display="always" Required="false" Mask="false">/mnt/user/media/local/</Config>
  <Config Name="Transcode Cache" Target="/temp" Default="" Mode="rw" Description="Container Path: /temp" Type="Path" Display="always" Required="false" Mask="false">/mnt/user/temp/tdarr_transcode/</Config>
  <Config Name="Nvidia Visible Devices" Target="NVIDIA_VISIBLE_DEVICES" Default="" Mode="" Description="Nvidia Visible Devices (Optional - Requires Nvidia GPU and Unraid Nvidia build)" Type="Variable" Display="always" Required="false" Mask="false">GPU-01981fdf-d4b2-4e74-ed8c-c3dcb8629146</Config>
  <Config Name="Nvidia Driver Capabilities" Target="NVIDIA_DRIVER_CAPABILITIES" Default="all" Mode="" Description="Container Variable: NVIDIA_DRIVER_CAPABILITIES" Type="Variable" Display="always" Required="false" Mask="false">all</Config>
  <Config Name="Node ID" Target="nodeID" Default="" Mode="" Description="Container Variable: nodeID" Type="Variable" Display="always" Required="false" Mask="false">LoyalSlaveNode</Config>
</Container>
